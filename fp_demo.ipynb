{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eight-screw",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "marine-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need these\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "restricted-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-acrobat",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monetary-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_time_res(fname):\n",
    "    \"\"\"Read the time resolution from file.\"\"\"\n",
    "    with open(fname) as f:\n",
    "        for i in range(8):\n",
    "            f.readline()\n",
    "        d = f.readline()\n",
    "    return np.array([float(element) for element in d.strip().split()])\n",
    "\n",
    "def read_data(fname):\n",
    "    \"\"\"Load the counts from file.\"\"\"\n",
    "    return np.loadtxt(fname, dtype=int, skiprows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-conversion",
   "metadata": {},
   "source": [
    "# Load and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eligible-bloom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 3],\n",
       "       [5, 3],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = \"palato_260421_1.dat\"\n",
    "data = read_data(fname)[:,3:5] # load columns 3 and 4\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-finding",
   "metadata": {},
   "source": [
    "Our `data` variable now contains a the counts in a 2D table. Above we see an abbreviated version of it, the complete array is very long. We can check its shape, as `(rows, columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electronic-qatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32768, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape) # we have 32768 rows and 2 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-birthday",
   "metadata": {},
   "source": [
    "We can select elements from the data. The first index corresponds to rows, the second index corresponds to columns. `python` indexes starting with 0, so the first column is column 0, the second column is column 1, etc.\n",
    "\n",
    "To specify a range, we can write `variable[start:stop:step]`. The section `start:stop:step` is called a `slice`. `stop` is excluded. We can ask for one slice per axis. If `start` or `stop` are missing, it means \"from start\" or \"until the end\". If `step` is ommited, it defaults to 1.\n",
    "\n",
    "The following line will print elements at index `5,7,9` from column number 1. Remember that column number 1 is the second column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "simplified-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  19,    1, 1408])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[5:10:2, 1]  # this reads as: select rows 5 to 10 by steps of 2, and second column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-lunch",
   "metadata": {},
   "source": [
    "To select a single column, we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secure-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-introduction",
   "metadata": {},
   "source": [
    "We can check the time delay per bin, in ns per bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "entire-dollar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "time_per_bin = read_time_res(fname)[3:5]\n",
    "print(time_per_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-moldova",
   "metadata": {},
   "source": [
    "It's the same in both cases, so we just keep one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smooth-tracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "dt = time_per_bin[0]\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-steps",
   "metadata": {},
   "source": [
    "Our time delays are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floating-profit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e-01, 2.0000e-01, ..., 3.2765e+03, 3.2766e+03,\n",
       "       3.2767e+03])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = np.arange(data.shape[0])*dt\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-james",
   "metadata": {},
   "source": [
    "# Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abstract-canvas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356fc75c07c0454bb0029bf5698fd99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure() # create a figure. We can specify the size, resolution, etc, here.\n",
    "# we can control the style here, if we don't like the defaults. `lw` stands for `linewidth`.\n",
    "plt.plot(times, data[:,0], lw=0.5, label=\"curve 1?\") \n",
    "plt.plot(times, data[:,1], lw=0.5, label=\"curve 2?\") \n",
    "plt.yscale(\"symlog\") # use the \"symlog\" scale along y. \n",
    "# \"symlog\" uses a log scale for the y axis, except for values around 0, where a linear scale is used\n",
    "plt.xlim(-50, 800) # set the x limits of the plot\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Time (ns)\")\n",
    "# A a legend. The simplest way is to pass a label for every call to `plot`, and just let the legend build itself.\n",
    "plt.legend(title=\"...\")\n",
    "plt.tight_layout() # it's better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-tribute",
   "metadata": {},
   "source": [
    "There is something off in the early part. You should be able to zoom in on the early part using the controls of the interactive plot. Otherwise, we can change the limits manually as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adult-bahamas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da336dc6a67844a483e3297116c24f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(times, data[:,0], lw=0.5, label=\"curve 1?\") \n",
    "plt.plot(times, data[:,1], lw=0.5, label=\"curve 2?\") \n",
    "plt.yscale(\"symlog\") \n",
    "plt.xlim(-10, 20) # set the x limits of the plot\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Time (ns)\")\n",
    "# A a legend. The simplest way is to pass a label for every call to `plot`, and just let the legend build itself.\n",
    "plt.tight_layout() # it's better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-warren",
   "metadata": {},
   "source": [
    "Suscpicious... Keep in mind this is on log scale, so that early spike is actually very large. In linear scale, it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "marked-conditions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73be36eab18844c6b29dec9f7261dba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure() \n",
    "plt.plot(times, data[:,0], lw=0.5, label=\"curve 1?\") \n",
    "plt.plot(times, data[:,1], lw=0.5, label=\"curve 2?\") \n",
    "plt.xlim(-5, 20) # set the x limits of the plot\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Time (ns)\")\n",
    "plt.tight_layout() # it's better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-update",
   "metadata": {},
   "source": [
    "It seems the IRF is leaking through. We should investigate this more carefully. In the meantime, we can estimate $t_0$ to about 0.8 ns. We should also remove the weird early part from the analysis. Let's define a lower time limit at 5 ns, and remove everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "underlying-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 0.8\n",
    "limit_low = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-johns",
   "metadata": {},
   "source": [
    "The array `is_valid` contains `True` or `False`, depending on our lower time limit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "strange-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_valid = times > limit_low\n",
    "is_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-crest",
   "metadata": {},
   "source": [
    "The method `compress` will remove regions where `is_valid` is `False`, therefore eliminating the early part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "apart-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_valid = times > limit_low # i'm repeating this to avoid errors after multiple executions.\n",
    "times = np.compress(is_valid, times)\n",
    "# data is 2D, so we need to say if we want to operate along rows (axis 0) or columns (axis 1)\n",
    "data = np.compress(is_valid, data, axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-mauritius",
   "metadata": {},
   "source": [
    "By showing the graph again, we can see the early part has been eliminated. I want to emphasize that fixing data like this should be avoided as much as possible. Performing a better experiment is infinitely superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "natural-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099b9f375485451a89ad3fdc767a8ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure() \n",
    "plt.plot(times, data[:,0], label=\"curve 1?\") \n",
    "plt.plot(times, data[:,1], label=\"curve 2?\") \n",
    "plt.xlim(-5, 20) \n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Time (ns)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-anthony",
   "metadata": {},
   "source": [
    "# Onto fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-spine",
   "metadata": {},
   "source": [
    "Non-linear least-squares curve fits try to fit (ie: adjust) a curve to the data by finding the best parameters for the curve. Scientifically, we need to have a model for how our observations (eg: counts $I$) depend on the independent variable (eg: time $t$). In the case of chemical kinetics and fluorescence lifetime in particular, this is often a sum of expontential decays. We therefore have, for example:\n",
    "$$\n",
    "y_\\mathrm{fit}(t) = a_0e^{-t/\\tau_0}\n",
    "$$\n",
    "In this case, the fitting routine will try to find the values of $a_0$, $\\tau_0$. Note that $I_\\mathrm{fit}(t)$ depends linearly on $a_0$, but depends non-linearly on $\\tau_0$ ($\\tau_0$ is in the exponential). The nonlinear dependance of the parameters requires the use of nonlinear fitting routines.\n",
    "\n",
    "The fitting routine will find the values of ($a_0$, $\\tau_0$) which result in the best correspondance between the observations $y_\\mathrm{obs}$ and the fitted values $y_\\mathrm{fit}$. The most common choice is to minimize the sum of the squared residuals, weighted by the uncertainties $\\epsilon_i$:\n",
    "$$\n",
    "\\chi^2 = \\sum_i \\frac{\\left(y_{\\mathrm{obs},i}-y_{\\mathrm{fit},i}\\right)^2}{\\epsilon_i}\n",
    "$$\n",
    "where the index $i$ runs over data points. $\\chi^2$ is called the objective function, it's minimum should give us the best result. Note that other choices of objective functions are possible, but this is the most common.\n",
    "\n",
    "The role of the fitting algorithm is therefore to systematically vary the parameters in order to find the values that minimize $\\chi^2$. In principle, you could do this by hand (if you are very patient), but that sort of tedious detailed work is best left to computers.\n",
    "\n",
    "There are mulitple methods to vary the parameters. In most cases, they should be starting from a decent \"initial guess\", and the algorithm will systematically adjust the parameters in search of the minimum.\n",
    "\n",
    "*Initial guess*\n",
    "\n",
    "*bounds*\n",
    "\n",
    "*note on constraints*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-newport",
   "metadata": {},
   "source": [
    "Luckily, we are not the first ones to try a non-linear least squares. Indeed, this is a active area of research, and a common task across science and engineering. Here, we will use a module called `lmfit`. This module lets us define our own custom fit functions, and takes care of how to make this compatible with existing non-linear curve fitting routines.\n",
    "\n",
    "Here, we will define our own fit function, and use `lmfit` to carry out the fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "double-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_exp(x, a0, tau0, t0): # we can use any variable for the independant variable, but `x` is the default.\n",
    "    xr = x-t0\n",
    "    y = np.zeros_like(x) # an array full of 0, same shape as x\n",
    "    y[x > t0] = a0*np.exp(-xr/tau0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-ending",
   "metadata": {},
   "source": [
    "We now try our model, and see how a guess compares to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "detailed-nashville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241c25c4246341d5ae53116d20750fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-50.0, 800.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guessed_data = single_exp(times, 1E3, 50, t0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(times, data[:,1], label=\"curve 1?\") \n",
    "plt.plot(times, guessed_data, color=\"r\") # red!\n",
    "plt.yscale(\"symlog\")\n",
    "plt.xlim(-50, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-literature",
   "metadata": {},
   "source": [
    "It could clearly be better, but for such a simple model that's good enough. We can feed our model to `lmfit`, setup an inital guess and add some bounds to our data.\n",
    "\n",
    "Here we create the `Model` object, and create a set of initial parameters called `guess`. We can see that the code has correctly understood our function has 3 parameters, called `a0`, `tau0` and `t0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "burning-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th> name </th><th> value </th><th> initial value </th><th> min </th><th> max </th><th> vary </th></tr><tr><td> a0 </td><td>        -inf </td><td> None </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> tau0 </td><td>        -inf </td><td> None </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> t0 </td><td>        -inf </td><td> None </td><td>        -inf </td><td>         inf </td><td> True </td></tr></table>"
      ],
      "text/plain": [
       "Parameters([('a0', <Parameter 'a0', value=-inf, bounds=[-inf:inf]>),\n",
       "            ('tau0', <Parameter 'tau0', value=-inf, bounds=[-inf:inf]>),\n",
       "            ('t0', <Parameter 't0', value=-inf, bounds=[-inf:inf]>)])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lmfit.Model(single_exp) # some programming magic happens here...\n",
    "guess = model.make_params()\n",
    "guess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-order",
   "metadata": {},
   "source": [
    "We now set up the initial guess, using the values we tried above. We also set minimum bounds to `a0` and `tau0`, so they cannot be negative. Such critera of course depend on the specific problem.\n",
    "\n",
    " Varying `t0` would also be a problem in this specific case. In order to let the fitting algorithm adjust it, we would need to take the IRF into account. Luckily, our dynamics occur on timescales which are way longer, so it has no impact. We set the value of `t0` to the value we determined earlier, and don't vary it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "recorded-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th> name </th><th> value </th><th> initial value </th><th> min </th><th> max </th><th> vary </th></tr><tr><td> a0 </td><td>  1000.00000 </td><td> None </td><td>  0.00000000 </td><td>         inf </td><td> True </td></tr><tr><td> tau0 </td><td>  50.0000000 </td><td> None </td><td>  0.00000000 </td><td>         inf </td><td> True </td></tr><tr><td> t0 </td><td>  0.80000000 </td><td> None </td><td>        -inf </td><td>         inf </td><td> False </td></tr></table>"
      ],
      "text/plain": [
       "Parameters([('a0', <Parameter 'a0', value=1000.0, bounds=[0:inf]>),\n",
       "            ('tau0', <Parameter 'tau0', value=50, bounds=[0:inf]>),\n",
       "            ('t0', <Parameter 't0', value=0.8 (fixed), bounds=[-inf:inf]>)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess[\"a0\"].set(value=1E3, min=0) # initial value, same as above, minimum value=0\n",
    "guess[\"tau0\"].set(value=50, min=0)\n",
    "guess[\"t0\"].set(value=t0, vary=False) # varying the value of t0 will not work in this case; we keep it frozen \n",
    "guess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-botswana",
   "metadata": {},
   "source": [
    "Good, now we fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "national-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2> Model</h2> Model(single_exp) <h2>Fit Statistics</h2><table><tr><td>fitting method</td><td>leastsq</td><td></td></tr><tr><td># function evals</td><td>16</td><td></td></tr><tr><td># data points</td><td>32717</td><td></td></tr><tr><td># variables</td><td>2</td><td></td></tr><tr><td>chi-square</td><td> 468977.066</td><td></td></tr><tr><td>reduced chi-square</td><td> 14.3352305</td><td></td></tr><tr><td>Akaike info crit.</td><td> 87118.2160</td><td></td></tr><tr><td>Bayesian info crit.</td><td> 87135.0073</td><td></td></tr></table><h2>Variables</h2><table><tr><th> name </th><th> value </th><th> standard error </th><th> relative error </th><th> initial value </th><th> min </th><th> max </th><th> vary </th></tr><tr><td> a0 </td><td>  555.425040 </td><td>  0.32952042 </td><td> (0.06%) </td><td> 1000.0 </td><td>  0.00000000 </td><td>         inf </td><td> True </td></tr><tr><td> tau0 </td><td>  67.8300999 </td><td>  0.05346136 </td><td> (0.08%) </td><td> 50 </td><td>  0.00000000 </td><td>         inf </td><td> True </td></tr><tr><td> t0 </td><td>  0.80000000 </td><td>  0.00000000 </td><td> (0.00%) </td><td> 0.8 </td><td>        -inf </td><td>         inf </td><td> False </td></tr></table><h2>Correlations (unreported correlations are < 0.100)</h2><table><tr><td>a0</td><td>tau0</td><td>-0.7475</td></tr></table>"
      ],
      "text/plain": [
       "<lmfit.model.ModelResult at 0x2663a249e80>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.fit(data[:,1], guess, x=times)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "documentary-decade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dc76423187492e9d1b0ddc9ac1c10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-50.0, 800.0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(times, data[:,1])\n",
    "plt.plot(times, result.best_fit)\n",
    "plt.yscale(\"symlog\")\n",
    "plt.xlim(-50, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "personalized-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1E-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "joint-opera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2> Model</h2> Model(single_exp) <h2>Fit Statistics</h2><table><tr><td>fitting method</td><td>Nelder-Mead</td><td></td></tr><tr><td># function evals</td><td>104</td><td></td></tr><tr><td># data points</td><td>32717</td><td></td></tr><tr><td># variables</td><td>2</td><td></td></tr><tr><td>chi-square</td><td> 468977.066</td><td></td></tr><tr><td>reduced chi-square</td><td> 14.3352305</td><td></td></tr><tr><td>Akaike info crit.</td><td> 87118.2160</td><td></td></tr><tr><td>Bayesian info crit.</td><td> 87135.0073</td><td></td></tr></table><h2>Variables</h2><table><tr><th> name </th><th> value </th><th> initial value </th><th> min </th><th> max </th><th> vary </th></tr><tr><td> a0 </td><td>  555.424864 </td><td> 1000.0 </td><td>  0.00000000 </td><td>         inf </td><td> True </td></tr><tr><td> tau0 </td><td>  67.8301333 </td><td> 50 </td><td>  0.00000000 </td><td>         inf </td><td> True </td></tr><tr><td> t0 </td><td>  0.80000000 </td><td> 0.8 </td><td>        -inf </td><td>         inf </td><td> False </td></tr></table>"
      ],
      "text/plain": [
       "<lmfit.model.ModelResult at 0x266410ee630>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.fit(data[:,1], guess, x=times, method=\"nedler\", )\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aboriginal-housing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8b8e95e07f494980faa55ab485aec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-50.0, 800.0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(times, data[:,1])\n",
    "plt.plot(times, result.best_fit)\n",
    "plt.yscale(\"symlog\")\n",
    "plt.xlim(-50, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cross-sydney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d68d12d9ea642a884953f71c44d84f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-50.0, 300.0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(times, result.residual, lw=0.5)\n",
    "plt.plot(times, np.zeros_like(times))\n",
    "plt.xlim(-50, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "violent-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_exp(x, a0, a1, tau0, tau1, t0): # we can use any variable for the independant variable, but `x` is the default.\n",
    "    xr = x-t0\n",
    "    y = np.zeros_like(x) # an array full of 0, same shape as x\n",
    "    y[x > t0] = a0*np.exp(-xr/tau0)+a1*np.exp(-xr/tau1)\n",
    "    return y\n",
    "\n",
    "model = lmfit.Model(double_exp) # some programming magic happens here...\n",
    "guess = model.make_params()\n",
    "guess[\"a0\"].set(value=1E2) # initial value, same as above, minimum value=0\n",
    "guess[\"tau0\"].set(value=100, min=20)\n",
    "guess[\"a1\"].set(value=1E2) # initial value, same as above, minimum value=0\n",
    "guess[\"tau1\"].set(value=10, min=0.1)\n",
    "guess[\"t0\"].set(value=t0, vary=False) # varying the value of t0 will not work in this case; we keep it frozen \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "united-teaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2> Model</h2> Model(double_exp) <h2>Fit Statistics</h2><table><tr><td>fitting method</td><td>leastsq</td><td></td></tr><tr><td># function evals</td><td>36</td><td></td></tr><tr><td># data points</td><td>32717</td><td></td></tr><tr><td># variables</td><td>4</td><td></td></tr><tr><td>chi-square</td><td> 345368.462</td><td></td></tr><tr><td>reduced chi-square</td><td> 10.5575295</td><td></td></tr><tr><td>Akaike info crit.</td><td> 77112.7111</td><td></td></tr><tr><td>Bayesian info crit.</td><td> 77146.2937</td><td></td></tr></table><h2>Variables</h2><table><tr><th> name </th><th> value </th><th> standard error </th><th> relative error </th><th> initial value </th><th> min </th><th> max </th><th> vary </th></tr><tr><td> a0 </td><td>  512.233865 </td><td>  0.76236210 </td><td> (0.15%) </td><td> 100.0 </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> a1 </td><td>  135.915363 </td><td>  1.54228029 </td><td> (1.13%) </td><td> 100.0 </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> tau0 </td><td>  72.5416250 </td><td>  0.08853589 </td><td> (0.12%) </td><td> 100 </td><td>  20.0000000 </td><td>         inf </td><td> True </td></tr><tr><td> tau1 </td><td>  9.85052817 </td><td>  0.17858621 </td><td> (1.81%) </td><td> 10 </td><td>  0.10000000 </td><td>         inf </td><td> True </td></tr><tr><td> t0 </td><td>  0.80000000 </td><td>  0.00000000 </td><td> (0.00%) </td><td> 0.8 </td><td>        -inf </td><td>         inf </td><td> False </td></tr></table><h2>Correlations (unreported correlations are < 0.100)</h2><table><tr><td>a0</td><td>tau0</td><td>-0.9121</td></tr><tr><td>a0</td><td>tau1</td><td>-0.7944</td></tr><tr><td>tau0</td><td>tau1</td><td>0.6490</td></tr><tr><td>a1</td><td>tau1</td><td>-0.6026</td></tr></table>"
      ],
      "text/plain": [
       "<lmfit.model.ModelResult at 0x26656061a90>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.fit(data[:,1], guess, x=times)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "unauthorized-firmware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4471ef7853814803b55560515bf9fd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-50.0, 800.0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(times, data[:,1])\n",
    "plt.plot(times, result.best_fit)\n",
    "plt.yscale(\"symlog\")\n",
    "plt.xlim(-50, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "acceptable-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e27a3e970f4e2da047201f9b1054fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-50.0, 300.0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(times, result.residual, lw=0.5)\n",
    "plt.plot(times, np.zeros_like(times))\n",
    "plt.xlim(-50, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "flying-harrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2> Model</h2> Model(double_exp) <h2>Fit Statistics</h2><table><tr><td>fitting method</td><td>Nelder-Mead</td><td></td></tr><tr><td># function evals</td><td>448</td><td></td></tr><tr><td># data points</td><td>32717</td><td></td></tr><tr><td># variables</td><td>4</td><td></td></tr><tr><td>chi-square</td><td> 239809.797</td><td></td></tr><tr><td>reduced chi-square</td><td> 7.33071858</td><td></td></tr><tr><td>Akaike info crit.</td><td> 65178.6699</td><td></td></tr><tr><td>Bayesian info crit.</td><td> 65212.2525</td><td></td></tr></table><h2>Variables</h2><table><tr><th> name </th><th> value </th><th> initial value </th><th> min </th><th> max </th><th> vary </th></tr><tr><td> a0 </td><td>  507.219746 </td><td> 100.0 </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> a1 </td><td> -452.169979 </td><td> -100.0 </td><td>        -inf </td><td>         inf </td><td> True </td></tr><tr><td> tau0 </td><td>  70.8233628 </td><td> 100 </td><td>  20.0000000 </td><td>         inf </td><td> True </td></tr><tr><td> tau1 </td><td>  26.2083681 </td><td> 10 </td><td>  0.10000000 </td><td>         inf </td><td> True </td></tr><tr><td> t0 </td><td>  0.80000000 </td><td> 0.8 </td><td>        -inf </td><td>         inf </td><td> False </td></tr></table>"
      ],
      "text/plain": [
       "<lmfit.model.ModelResult at 0x266560320b8>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = model.make_params()\n",
    "guess[\"a0\"].set(value=1E2) # initial value, same as above, minimum value=0\n",
    "guess[\"tau0\"].set(value=100, min=20)\n",
    "guess[\"a1\"].set(value=-1E2) # initial value, same as above, minimum value=0\n",
    "guess[\"tau1\"].set(value=10, min=0.1)\n",
    "guess[\"t0\"].set(value=t0, vary=False) # varying the value of t0 will not work in this case; we keep it frozen \n",
    "\n",
    "result = model.fit(data[:,0], guess, x=times, method=\"nedler\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "comparative-bracelet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7015d283e9489ea7c1eb9212cbb12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-50.0, 800.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(times, data[:,0])\n",
    "plt.plot(times, result.best_fit)\n",
    "plt.yscale(\"symlog\")\n",
    "plt.xlim(-50, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-sender",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-reading",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
